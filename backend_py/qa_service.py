"""
1.3.30: QAé—®ç­”æœåŠ¡æ¨¡å—
æä¾›QAé—®ç­”çš„åˆ›å»ºã€æ‰¹é‡ä¸Šä¼ ã€æŸ¥è¯¢ã€æ›´æ–°ã€åˆ é™¤ç­‰åŠŸèƒ½
1.3.31: æ·»åŠ QAå‘é‡å­˜å‚¨å’ŒåŒ¹é…åŠŸèƒ½
"""

import os
import io
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import openpyxl
from supabase import Client
from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv
from pathlib import Path

# 1.3.36: å¯¼å…¥Embeddingç¼“å­˜æ¨¡å—
from embedding_cache import embed_query_with_cache

# 1.3.31: ç¡®ä¿ç¯å¢ƒå˜é‡å·²åŠ è½½ï¼ˆè§£å†³å¯¼å…¥é¡ºåºé—®é¢˜ï¼‰
# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
_current_dir = Path(__file__).parent
load_dotenv(_current_dir / '.env.local')
load_dotenv(_current_dir / '.env')

# 1.3.31: å‘é‡æ•°æ®åº“é…ç½®
USE_PGVECTOR = os.getenv("USE_PGVECTOR", "false").lower() == "true"
DATABASE_URL = os.getenv("PGVECTOR_DATABASE_URL") or os.getenv("DATABASE_URL")

# 1.3.31: QAå‘é‡åŒ¹é…é˜ˆå€¼ï¼ˆä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
QA_MATCH_THRESHOLD = float(os.getenv("QA_MATCH_THRESHOLD", "0.85"))

# 1.3.31: æ¡ä»¶å¯¼å…¥vecs
vecs = None
if USE_PGVECTOR and DATABASE_URL:
    try:
        import vecs as vecs_module
        vecs = vecs_module
    except ImportError:
        pass

# 1.3.30: é…ç½®æ—¥å¿—è®°å½•å™¨
logger = logging.getLogger(__name__)


def get_qa_collection_name(collection_name: str) -> str:
    """
    1.3.31: è·å–QAå‘é‡é›†åˆåç§°
    åœ¨åŸçŸ¥è¯†åº“é›†åˆåç§°åæ·»åŠ _qaåç¼€
    """
    return f"{collection_name}_qa"


class QAService:
    """
    1.3.30: QAé—®ç­”æœåŠ¡ç±»
    å¤„ç†QAé—®ç­”çš„CRUDæ“ä½œå’Œæ‰¹é‡ä¸Šä¼ 
    1.3.31: æ·»åŠ å‘é‡å­˜å‚¨å’ŒåŒ¹é…åŠŸèƒ½
    """
    
    def __init__(self, supabase: Client):
        """åˆå§‹åŒ–QAæœåŠ¡"""
        self.supabase = supabase
        self.embeddings = OpenAIEmbeddings()
    
    def _get_vector_collection(self, collection_name: str):
        """
        1.3.31: è·å–æˆ–åˆ›å»ºQAå‘é‡é›†åˆ
        1.3.32: æ¸…ç†è°ƒè¯•æ—¥å¿—
        """
        if not USE_PGVECTOR or not vecs or not DATABASE_URL:
            return None
        
        try:
            vx = vecs.create_client(DATABASE_URL)
            qa_collection_name = get_qa_collection_name(collection_name)
            
            try:
                collection = vx.get_collection(name=qa_collection_name)
            except Exception:
                # åˆ›å»ºæ–°é›†åˆ
                collection = vx.create_collection(
                    name=qa_collection_name,
                    dimension=1536  # OpenAI embeddings ç»´åº¦
                )
                logger.info(f"Created QA collection: {qa_collection_name}")
            
            return collection
        except Exception as e:
            logger.error(f"Error getting QA collection: {e}")
            return None
    
    def store_qa_to_vector(
        self,
        qa_id: str,
        collection_name: str,
        question: str,
        answer: str,
        similar_questions: List[str] = None
    ) -> bool:
        """
        1.3.31: å°†QAå­˜å…¥å‘é‡æ•°æ®åº“
        
        Args:
            qa_id: QAè®°å½•ID
            collection_name: çŸ¥è¯†åº“å‘é‡é›†åˆåç§°
            question: ä¸»é—®é¢˜
            answer: ç­”æ¡ˆ
            similar_questions: ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
        
        Returns:
            æ˜¯å¦å­˜å‚¨æˆåŠŸ
        """
        logger.debug(f"store_qa_to_vector called: qa_id={qa_id}, collection={collection_name}")
        
        if not USE_PGVECTOR or not vecs or not DATABASE_URL:
            logger.warning("pgvector not configured, skipping QA vector storage")
            return False
        
        try:
            collection = self._get_vector_collection(collection_name)
            # 1.3.32: ä½¿ç”¨ is None æ£€æŸ¥ï¼Œå› ä¸º vecs.Collection çš„ __bool__ è¿”å› False
            if collection is None:
                logger.error("Failed to get vector collection")
                return False
            
            # å‡†å¤‡æ‰€æœ‰è¦å‘é‡åŒ–çš„é—®é¢˜
            all_questions = [question]
            if similar_questions:
                all_questions.extend(similar_questions)
            
            # ç”Ÿæˆå‘é‡
            vectors = self.embeddings.embed_documents(all_questions)
            logger.debug(f"Generated {len(vectors)} vectors for QA")
            
            # å‡†å¤‡è®°å½•
            records = []
            qa_collection_name = get_qa_collection_name(collection_name)
            
            for i, (q, vec) in enumerate(zip(all_questions, vectors)):
                record_id = f"{qa_collection_name}_{qa_id}_{i}"
                metadata = {
                    "qa_id": qa_id,
                    "question": q,
                    "answer": answer,
                    "is_main": i == 0,  # æ˜¯å¦æ˜¯ä¸»é—®é¢˜
                    "text": q  # ç”¨äºæ£€ç´¢æ—¶è¿”å›
                }
                records.append((record_id, vec, metadata))
            
            # æ‰¹é‡æ’å…¥
            collection.upsert(records=records)
            
            logger.info(f"Stored {len(records)} QA vectors for qa_id: {qa_id}")
            return True
            
        except Exception as e:
            logger.error(f"Error storing QA to vector: {e}")
            return False
    
    def delete_qa_from_vector(self, qa_id: str, collection_name: str) -> bool:
        """
        1.3.31: ä»å‘é‡æ•°æ®åº“åˆ é™¤QA
        1.3.32: ä¿®å¤ is None æ£€æŸ¥
        """
        if not USE_PGVECTOR or not vecs or not DATABASE_URL:
            return False
        
        try:
            collection = self._get_vector_collection(collection_name)
            if collection is None:
                return False
            
            qa_collection_name = get_qa_collection_name(collection_name)
            # åˆ é™¤è¯¥QAçš„æ‰€æœ‰å‘é‡è®°å½•ï¼ˆä¸»é—®é¢˜å’Œç›¸ä¼¼é—®é¢˜ï¼‰
            # vecsä¸æ”¯æŒç›´æ¥åˆ é™¤ï¼Œéœ€è¦ç”¨ç©ºè®°å½•è¦†ç›–æˆ–ä½¿ç”¨SQL
            # è¿™é‡Œæˆ‘ä»¬é€šè¿‡Supabaseç›´æ¥æ“ä½œ
            try:
                # ä½¿ç”¨Supabase SQLåˆ é™¤
                self.supabase.rpc(
                    'delete_qa_vectors',
                    {'qa_id_prefix': f"{qa_collection_name}_{qa_id}_"}
                ).execute()
            except:
                # å¦‚æœRPCä¸å­˜åœ¨ï¼Œå¿½ç•¥ï¼ˆå‘é‡ä¼šåœ¨ä¸‹æ¬¡æ›´æ–°æ—¶è¢«è¦†ç›–ï¼‰
                pass
            
            return True
        except Exception as e:
            logger.error(f"Error deleting QA from vector: {e}")
            return False
    
    def match_qa(
        self,
        collection_name: str,
        query: str,
        threshold: float = None
    ) -> Optional[Dict[str, Any]]:
        """
        1.3.31: åœ¨QAå‘é‡åº“ä¸­åŒ¹é…é—®é¢˜
        
        Args:
            collection_name: çŸ¥è¯†åº“å‘é‡é›†åˆåç§°
            query: ç”¨æˆ·é—®é¢˜
            threshold: åŒ¹é…é˜ˆå€¼ï¼ˆé»˜è®¤ä½¿ç”¨QA_MATCH_THRESHOLDï¼‰
        
        Returns:
            åŒ¹é…åˆ°çš„QAè®°å½•ï¼ŒåŒ…å«answerå’Œscoreï¼Œå¦‚æœæ²¡æœ‰åŒ¹é…è¿”å›None
        """
        if not USE_PGVECTOR or not vecs or not DATABASE_URL:
            return None
        
        if threshold is None:
            threshold = QA_MATCH_THRESHOLD
        
        try:
            collection = self._get_vector_collection(collection_name)
            # 1.3.33: ä½¿ç”¨ is None æ£€æŸ¥ï¼Œå› ä¸º vecs.Collection çš„ __bool__ è¿”å› False
            if collection is None:
                if os.getenv("ENV") == "development":
                    print(f"âš ï¸ QA collection not found for: {collection_name}")
                return None
            
            if os.getenv("ENV") == "development":
                print(f"ğŸ” Matching QA in collection: {get_qa_collection_name(collection_name)}")
            
            # 1.3.36: ä½¿ç”¨ç¼“å­˜ç‰ˆæœ¬çš„embed_queryï¼Œé¿å…é‡å¤è°ƒç”¨OpenAI API
            query_vector = embed_query_with_cache(query)
            
            # æŸ¥è¯¢æœ€ç›¸ä¼¼çš„QA
            results = collection.query(
                data=query_vector,
                limit=1,
                include_value=True,
                include_metadata=True
            )
            
            if os.getenv("ENV") == "development":
                print(f"ğŸ” QA query results: {results}")
            
            if not results:
                if os.getenv("ENV") == "development":
                    print(f"âš ï¸ No QA results found")
                return None
            
            # è§£æç»“æœ
            record = results[0]
            if len(record) >= 3:
                record_id = record[0]
                score = record[1]
                metadata = record[2] if record[2] else {}
            else:
                return None
            
            # vecsä½¿ç”¨å†…ç§¯è·ç¦»ï¼Œéœ€è¦è½¬æ¢ä¸ºç›¸ä¼¼åº¦
            # å¯¹äºå½’ä¸€åŒ–å‘é‡ï¼Œå†…ç§¯è·ç¦» = 1 - ä½™å¼¦ç›¸ä¼¼åº¦
            # æ‰€ä»¥ç›¸ä¼¼åº¦ = 1 - distance
            similarity = 1 - score if score is not None else 0
            
            if os.getenv("ENV") == "development":
                logger.info(f"QA match score: {similarity:.4f}, threshold: {threshold}")
            
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
            if similarity >= threshold:
                return {
                    "qa_id": metadata.get("qa_id"),
                    "question": metadata.get("question"),
                    "answer": metadata.get("answer"),
                    "score": similarity,
                    "matched": True
                }
            
            return None
            
        except Exception as e:
            logger.error(f"Error matching QA: {e}")
            return None
    
    def create_qa_item(
        self,
        knowledge_base_id: str,
        question: str,
        answer: str,
        similar_questions: List[str] = None,
        source: str = 'custom'
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºå•ä¸ªQAé—®ç­”
        1.3.31: åˆ›å»ºåè‡ªåŠ¨å­˜å…¥å‘é‡åº“
        
        Args:
            knowledge_base_id: çŸ¥è¯†åº“ID
            question: ä¸»é—®é¢˜
            answer: ç­”æ¡ˆ
            similar_questions: ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
            source: æ¥æº (custom/batch)
        
        Returns:
            åˆ›å»ºçš„QAè®°å½•
        """
        try:
            # è®¡ç®—ç­”æ¡ˆå­—æ•°
            word_count = len(answer)
            
            data = {
                'knowledge_base_id': knowledge_base_id,
                'question': question.strip(),
                'answer': answer.strip(),
                'similar_questions': similar_questions or [],
                'source': source,
                'word_count': word_count,
                'status': 'pending'  # åˆå§‹çŠ¶æ€ä¸ºå¾…å­¦ä¹ 
            }
            
            result = self.supabase.table('qa_items').insert(data).execute()
            
            if result.data:
                qa_item = result.data[0]
                qa_id = qa_item['id']
                logger.info(f"Created QA item: {qa_id}")
                
                # 1.3.31: è·å–çŸ¥è¯†åº“çš„vector_collectionå¹¶å­˜å…¥å‘é‡åº“
                try:
                    kb_result = self.supabase.table('knowledge_bases')\
                        .select('vector_collection')\
                        .eq('id', knowledge_base_id)\
                        .single()\
                        .execute()
                    
                    if kb_result.data and kb_result.data.get('vector_collection'):
                        collection_name = kb_result.data['vector_collection']
                        
                        # å­˜å…¥å‘é‡åº“
                        vector_success = self.store_qa_to_vector(
                            qa_id=qa_id,
                            collection_name=collection_name,
                            question=question.strip(),
                            answer=answer.strip(),
                            similar_questions=similar_questions
                        )
                        
                        # æ›´æ–°çŠ¶æ€
                        new_status = 'learned' if vector_success else 'failed'
                        self.supabase.table('qa_items')\
                            .update({'status': new_status})\
                            .eq('id', qa_id)\
                            .execute()
                        
                        qa_item['status'] = new_status
                        logger.info(f"QA item {qa_id} status updated to: {new_status}")
                    else:
                        logger.warning(f"Knowledge base {knowledge_base_id} has no vector_collection")
                        
                except Exception as e:
                    logger.error(f"Error storing QA to vector: {e}")
                    # æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                    self.supabase.table('qa_items')\
                        .update({'status': 'failed'})\
                        .eq('id', qa_id)\
                        .execute()
                    qa_item['status'] = 'failed'
                
                return {'success': True, 'data': qa_item}
            else:
                return {'success': False, 'error': 'Failed to create QA item'}
                
        except Exception as e:
            logger.error(f"Error creating QA item: {e}")
            return {'success': False, 'error': str(e)}
    
    def list_qa_items(
        self,
        knowledge_base_id: str,
        status: str = None,
        source: str = None,
        search: str = None,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """
        è·å–QAé—®ç­”åˆ—è¡¨
        
        Args:
            knowledge_base_id: çŸ¥è¯†åº“ID
            status: ç­›é€‰çŠ¶æ€
            source: ç­›é€‰æ¥æº
            search: æœç´¢å…³é”®è¯
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
        
        Returns:
            QAåˆ—è¡¨å’Œåˆ†é¡µä¿¡æ¯
        """
        try:
            query = self.supabase.table('qa_items').select('*', count='exact')
            query = query.eq('knowledge_base_id', knowledge_base_id)
            
            if status:
                query = query.eq('status', status)
            
            if source:
                query = query.eq('source', source)
            
            if search:
                # æœç´¢é—®é¢˜å†…å®¹
                query = query.ilike('question', f'%{search}%')
            
            # æ’åºå’Œåˆ†é¡µ
            offset = (page - 1) * page_size
            query = query.order('created_at', desc=True)
            query = query.range(offset, offset + page_size - 1)
            
            result = query.execute()
            
            total = result.count if result.count else 0
            total_pages = (total + page_size - 1) // page_size
            
            return {
                'success': True,
                'data': result.data or [],
                'pagination': {
                    'page': page,
                    'page_size': page_size,
                    'total': total,
                    'total_pages': total_pages
                }
            }
            
        except Exception as e:
            logger.error(f"Error listing QA items: {e}")
            return {'success': False, 'error': str(e), 'data': [], 'pagination': {}}
    
    def get_qa_item(self, qa_id: str) -> Dict[str, Any]:
        """
        è·å–å•ä¸ªQAé—®ç­”è¯¦æƒ…
        
        Args:
            qa_id: QA ID
        
        Returns:
            QAè¯¦æƒ…
        """
        try:
            result = self.supabase.table('qa_items').select('*').eq('id', qa_id).single().execute()
            
            if result.data:
                return {'success': True, 'data': result.data}
            else:
                return {'success': False, 'error': 'QA item not found'}
                
        except Exception as e:
            logger.error(f"Error getting QA item: {e}")
            return {'success': False, 'error': str(e)}
    
    def update_qa_item(
        self,
        qa_id: str,
        question: str = None,
        answer: str = None,
        similar_questions: List[str] = None,
        status: str = None
    ) -> Dict[str, Any]:
        """
        æ›´æ–°QAé—®ç­”
        1.3.33: å½“é—®é¢˜æˆ–ç›¸ä¼¼é—®é¢˜å˜æ›´æ—¶ï¼Œé‡æ–°å­˜å‚¨å‘é‡
        
        Args:
            qa_id: QA ID
            question: æ–°é—®é¢˜ï¼ˆå¯é€‰ï¼‰
            answer: æ–°ç­”æ¡ˆï¼ˆå¯é€‰ï¼‰
            similar_questions: æ–°ç›¸ä¼¼é—®é¢˜åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            status: æ–°çŠ¶æ€ï¼ˆå¯é€‰ï¼‰
        
        Returns:
            æ›´æ–°åçš„QAè®°å½•
        """
        try:
            data = {}
            need_reindex = False  # 1.3.33: æ˜¯å¦éœ€è¦é‡æ–°ç´¢å¼•å‘é‡
            
            if question is not None:
                data['question'] = question.strip()
                need_reindex = True  # é—®é¢˜å˜æ›´éœ€è¦é‡æ–°ç´¢å¼•
            
            if answer is not None:
                data['answer'] = answer.strip()
                data['word_count'] = len(answer)
                need_reindex = True  # ç­”æ¡ˆå˜æ›´éœ€è¦é‡æ–°ç´¢å¼•ï¼ˆå› ä¸ºmetadataåŒ…å«answerï¼‰
            
            if similar_questions is not None:
                data['similar_questions'] = similar_questions
                need_reindex = True  # ç›¸ä¼¼é—®é¢˜å˜æ›´éœ€è¦é‡æ–°ç´¢å¼•
            
            if status is not None:
                data['status'] = status
            
            if not data:
                return {'success': False, 'error': 'No data to update'}
            
            result = self.supabase.table('qa_items').update(data).eq('id', qa_id).execute()
            
            if result.data:
                updated_item = result.data[0]
                logger.info(f"Updated QA item: {qa_id}")
                
                # 1.3.33: å¦‚æœéœ€è¦é‡æ–°ç´¢å¼•å‘é‡
                if need_reindex:
                    try:
                        # è·å–çŸ¥è¯†åº“çš„vector_collection
                        kb_id = updated_item.get('knowledge_base_id')
                        kb_result = self.supabase.table('knowledge_bases')\
                            .select('vector_collection')\
                            .eq('id', kb_id)\
                            .limit(1)\
                            .execute()
                        
                        if kb_result.data and len(kb_result.data) > 0:
                            collection_name = kb_result.data[0].get('vector_collection')
                            if collection_name:
                                # è·å–å®Œæ•´çš„QAæ•°æ®
                                final_question = updated_item.get('question')
                                final_answer = updated_item.get('answer')
                                final_similar = updated_item.get('similar_questions') or []
                                
                                if os.getenv("ENV") == "development":
                                    print(f"ğŸ”„ é‡æ–°ç´¢å¼•QAå‘é‡: qa_id={qa_id}, question={final_question}, similar={final_similar}")
                                
                                # é‡æ–°å­˜å‚¨å‘é‡
                                vector_success = self.store_qa_to_vector(
                                    qa_id=qa_id,
                                    collection_name=collection_name,
                                    question=final_question,
                                    answer=final_answer,
                                    similar_questions=final_similar
                                )
                                
                                # æ›´æ–°çŠ¶æ€
                                new_status = 'learned' if vector_success else 'failed'
                                self.supabase.table('qa_items').update({'status': new_status}).eq('id', qa_id).execute()
                                updated_item['status'] = new_status
                                
                                if os.getenv("ENV") == "development":
                                    print(f"{'âœ…' if vector_success else 'âŒ'} å‘é‡é‡æ–°ç´¢å¼•{'æˆåŠŸ' if vector_success else 'å¤±è´¥'}")
                    except Exception as ve:
                        logger.error(f"Error re-indexing QA vector: {ve}")
                        if os.getenv("ENV") == "development":
                            print(f"âš ï¸ å‘é‡é‡æ–°ç´¢å¼•å¤±è´¥: {ve}")
                
                return {'success': True, 'data': updated_item}
            else:
                return {'success': False, 'error': 'Failed to update QA item'}
                
        except Exception as e:
            logger.error(f"Error updating QA item: {e}")
            return {'success': False, 'error': str(e)}
    
    def delete_qa_item(self, qa_id: str) -> Dict[str, Any]:
        """
        åˆ é™¤QAé—®ç­”
        1.3.33: åŒæ—¶åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„å¯¹åº”æ•°æ®å’Œqa_cacheç¼“å­˜
        
        Args:
            qa_id: QA ID
        
        Returns:
            åˆ é™¤ç»“æœ
        """
        try:
            # 1.3.33: å…ˆè·å–QAè®°å½•å®Œæ•´ä¿¡æ¯
            qa_result = self.supabase.table('qa_items')\
                .select('knowledge_base_id, question, similar_questions, answer')\
                .eq('id', qa_id)\
                .limit(1)\
                .execute()
            
            if qa_result.data and len(qa_result.data) > 0:
                qa_data = qa_result.data[0]
                kb_id = qa_data.get('knowledge_base_id')
                question = qa_data.get('question')
                similar_questions = qa_data.get('similar_questions') or []
                answer = qa_data.get('answer')
                
                # è·å–çŸ¥è¯†åº“çš„vector_collection
                if kb_id:
                    kb_result = self.supabase.table('knowledge_bases')\
                        .select('vector_collection')\
                        .eq('id', kb_id)\
                        .limit(1)\
                        .execute()
                    
                    if kb_result.data and len(kb_result.data) > 0:
                        collection_name = kb_result.data[0].get('vector_collection')
                        if collection_name:
                            # åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„æ•°æ®
                            self._delete_qa_vectors(qa_id, collection_name)
                    
                    # 1.3.33: åˆ é™¤qa_cacheä¸­ç›¸å…³çš„ç¼“å­˜
                    self._delete_qa_cache(kb_id, question, similar_questions, answer)
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            result = self.supabase.table('qa_items').delete().eq('id', qa_id).execute()
            
            logger.info(f"Deleted QA item: {qa_id}")
            return {'success': True, 'message': 'QA item deleted'}
            
        except Exception as e:
            logger.error(f"Error deleting QA item: {e}")
            return {'success': False, 'error': str(e)}
    
    def _delete_qa_cache(self, kb_id: str, question: str, similar_questions: List[str], answer: str) -> None:
        """
        1.3.33: åˆ é™¤qa_cacheä¸­ä¸è¯¥QAç›¸å…³çš„ç¼“å­˜è®°å½•
        
        åˆ é™¤ç­–ç•¥ï¼š
        1. åˆ é™¤è¯¥çŸ¥è¯†åº“ä¸­answerå®Œå…¨åŒ¹é…çš„ç¼“å­˜
        2. è¿™æ ·å¯ä»¥æ¸…é™¤ä¸»é—®é¢˜å’Œæ‰€æœ‰ç›¸ä¼¼é—®é¢˜çš„ç¼“å­˜
        
        Args:
            kb_id: çŸ¥è¯†åº“ID
            question: ä¸»é—®é¢˜
            similar_questions: ç›¸ä¼¼é—®é¢˜åˆ—è¡¨
            answer: ç­”æ¡ˆ
        """
        try:
            # åˆ é™¤è¯¥çŸ¥è¯†åº“ä¸­answerå®Œå…¨åŒ¹é…çš„ç¼“å­˜
            # å› ä¸ºä¸»é—®é¢˜å’Œç›¸ä¼¼é—®é¢˜çš„answeréƒ½æ˜¯ç›¸åŒçš„
            result = self.supabase.table('qa_cache')\
                .delete()\
                .eq('knowledge_base_id', kb_id)\
                .eq('answer', answer)\
                .execute()
            
            if os.getenv("ENV") == "development":
                print(f"ğŸ—‘ï¸ å·²æ¸…é™¤QAç›¸å…³ç¼“å­˜ (kb_id={kb_id}, answer={answer[:20]}...)")
            logger.info(f"Deleted QA cache for kb_id: {kb_id}")
            
        except Exception as e:
            logger.error(f"Error deleting QA cache: {e}")
            if os.getenv("ENV") == "development":
                print(f"âš ï¸ æ¸…é™¤QAç¼“å­˜å¤±è´¥: {e}")
    
    def _delete_qa_vectors(self, qa_id: str, collection_name: str) -> bool:
        """
        1.3.33: ä»å‘é‡æ•°æ®åº“ä¸­åˆ é™¤æŒ‡å®šQAçš„æ‰€æœ‰å‘é‡ï¼ˆåŒ…æ‹¬ä¸»é—®é¢˜å’Œç›¸ä¼¼é—®é¢˜ï¼‰
        
        Args:
            qa_id: QA ID
            collection_name: çŸ¥è¯†åº“å‘é‡é›†åˆåç§°
        
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        if not USE_PGVECTOR or not vecs or not DATABASE_URL:
            return False
        
        try:
            qa_collection_name = get_qa_collection_name(collection_name)
            
            # ä½¿ç”¨SQLç›´æ¥åˆ é™¤ï¼Œé¿å…å½±å“å…¶ä»–æ•°æ®
            # å‘é‡è®°å½•IDæ ¼å¼: {qa_collection_name}_{qa_id}_{index}
            id_prefix = f"{qa_collection_name}_{qa_id}_"
            
            from sqlalchemy import text
            vx = vecs.create_client(DATABASE_URL)
            
            with vx.engine.connect() as conn:
                # å…ˆæŸ¥è¯¢è¦åˆ é™¤çš„è®°å½•æ•°é‡
                count_result = conn.execute(text(f'''
                    SELECT COUNT(*) FROM vecs."{qa_collection_name}"
                    WHERE id LIKE :id_pattern
                '''), {"id_pattern": f"{id_prefix}%"})
                count = count_result.scalar()
                
                if count > 0:
                    # åˆ é™¤åŒ¹é…çš„è®°å½•
                    conn.execute(text(f'''
                        DELETE FROM vecs."{qa_collection_name}"
                        WHERE id LIKE :id_pattern
                    '''), {"id_pattern": f"{id_prefix}%"})
                    conn.commit()
                    
                    if os.getenv("ENV") == "development":
                        print(f"ğŸ—‘ï¸ å·²åˆ é™¤ {count} æ¡QAå‘é‡è®°å½• (qa_id={qa_id})")
                    logger.info(f"Deleted {count} QA vectors for qa_id: {qa_id}")
            
            return True
            
        except Exception as e:
            logger.error(f"Error deleting QA vectors: {e}")
            if os.getenv("ENV") == "development":
                print(f"âš ï¸ åˆ é™¤QAå‘é‡å¤±è´¥: {e}")
            return False
    
    def delete_qa_items_batch(self, qa_ids: List[str]) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆ é™¤QAé—®ç­”
        1.3.33: åŒæ—¶åˆ é™¤å‘é‡æ•°æ®åº“ä¸­çš„å¯¹åº”æ•°æ®å’Œqa_cacheç¼“å­˜
        
        Args:
            qa_ids: QA IDåˆ—è¡¨
        
        Returns:
            åˆ é™¤ç»“æœ
        """
        try:
            # 1.3.33: å…ˆè·å–æ‰€æœ‰QAçš„å®Œæ•´ä¿¡æ¯
            qa_result = self.supabase.table('qa_items')\
                .select('id, knowledge_base_id, question, similar_questions, answer')\
                .in_('id', qa_ids)\
                .execute()
            
            if qa_result.data:
                # æŒ‰knowledge_base_idåˆ†ç»„
                kb_qa_map = {}
                for qa in qa_result.data:
                    kb_id = qa.get('knowledge_base_id')
                    if kb_id:
                        if kb_id not in kb_qa_map:
                            kb_qa_map[kb_id] = {'qa_ids': [], 'qa_data': []}
                        kb_qa_map[kb_id]['qa_ids'].append(qa.get('id'))
                        kb_qa_map[kb_id]['qa_data'].append(qa)
                
                # è·å–æ¯ä¸ªçŸ¥è¯†åº“çš„vector_collectionå¹¶åˆ é™¤å‘é‡å’Œç¼“å­˜
                for kb_id, data in kb_qa_map.items():
                    kb_result = self.supabase.table('knowledge_bases')\
                        .select('vector_collection')\
                        .eq('id', kb_id)\
                        .limit(1)\
                        .execute()
                    
                    if kb_result.data and len(kb_result.data) > 0:
                        collection_name = kb_result.data[0].get('vector_collection')
                        if collection_name:
                            for qa_id in data['qa_ids']:
                                self._delete_qa_vectors(qa_id, collection_name)
                    
                    # 1.3.33: åˆ é™¤æ¯ä¸ªQAçš„ç¼“å­˜
                    for qa in data['qa_data']:
                        self._delete_qa_cache(
                            kb_id,
                            qa.get('question', ''),
                            qa.get('similar_questions') or [],
                            qa.get('answer', '')
                        )
            
            # åˆ é™¤æ•°æ®åº“è®°å½•
            result = self.supabase.table('qa_items').delete().in_('id', qa_ids).execute()
            
            logger.info(f"Deleted {len(qa_ids)} QA items")
            return {'success': True, 'message': f'Deleted {len(qa_ids)} QA items'}
            
        except Exception as e:
            logger.error(f"Error batch deleting QA items: {e}")
            return {'success': False, 'error': str(e)}
    
    def parse_xlsx(self, file_content: bytes) -> Dict[str, Any]:
        """
        è§£æxlsxæ–‡ä»¶å†…å®¹
        
        Args:
            file_content: xlsxæ–‡ä»¶äºŒè¿›åˆ¶å†…å®¹
        
        Returns:
            è§£æç»“æœï¼ŒåŒ…å«é—®ç­”åˆ—è¡¨
        """
        try:
            # ä½¿ç”¨openpyxlè¯»å–xlsx
            wb = openpyxl.load_workbook(io.BytesIO(file_content))
            ws = wb.active
            
            qa_list = []
            errors = []
            
            # è·³è¿‡æ ‡é¢˜è¡Œï¼ˆç¬¬1è¡Œæ˜¯è¯´æ˜ï¼Œç¬¬2è¡Œæ˜¯åˆ—åï¼‰
            for row_idx, row in enumerate(ws.iter_rows(min_row=3, values_only=True), start=3):
                if not row or all(cell is None for cell in row):
                    continue
                
                question_cell = row[0] if len(row) > 0 else None
                answer_cell = row[1] if len(row) > 1 else None
                
                if not question_cell or not answer_cell:
                    errors.append(f"ç¬¬{row_idx}è¡Œ: é—®é¢˜æˆ–ç­”æ¡ˆä¸ºç©º")
                    continue
                
                question_str = str(question_cell).strip()
                answer_str = str(answer_cell).strip()
                
                if not question_str or not answer_str:
                    errors.append(f"ç¬¬{row_idx}è¡Œ: é—®é¢˜æˆ–ç­”æ¡ˆä¸ºç©º")
                    continue
                
                # è§£æé—®é¢˜ï¼Œæ”¯æŒä½¿ç”¨|åˆ†éš”å¤šä¸ªé—®é¢˜
                questions = [q.strip() for q in question_str.split('|') if q.strip()]
                
                if not questions:
                    errors.append(f"ç¬¬{row_idx}è¡Œ: æ²¡æœ‰æœ‰æ•ˆçš„é—®é¢˜")
                    continue
                
                # ç¬¬ä¸€ä¸ªä½œä¸ºä¸»é—®é¢˜ï¼Œå…¶ä½™ä½œä¸ºç›¸ä¼¼é—®é¢˜
                main_question = questions[0]
                similar_questions = questions[1:] if len(questions) > 1 else []
                
                qa_list.append({
                    'question': main_question,
                    'answer': answer_str,
                    'similar_questions': similar_questions,
                    'row': row_idx
                })
            
            return {
                'success': True,
                'data': qa_list,
                'total': len(qa_list),
                'errors': errors
            }
            
        except Exception as e:
            logger.error(f"Error parsing xlsx: {e}")
            return {'success': False, 'error': str(e), 'data': [], 'total': 0, 'errors': []}
    
    def batch_upload(
        self,
        knowledge_base_id: str,
        file_content: bytes,
        filename: str,
        file_size: int
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡ä¸Šä¼ QAé—®ç­”
        
        Args:
            knowledge_base_id: çŸ¥è¯†åº“ID
            file_content: xlsxæ–‡ä»¶äºŒè¿›åˆ¶å†…å®¹
            filename: æ–‡ä»¶å
            file_size: æ–‡ä»¶å¤§å°
        
        Returns:
            ä¸Šä¼ ç»“æœ
        """
        try:
            # åˆ›å»ºä¸Šä¼ è®°å½•
            upload_record = self.supabase.table('qa_upload_records').insert({
                'knowledge_base_id': knowledge_base_id,
                'filename': filename,
                'file_size': file_size,
                'status': 'processing'
            }).execute()
            
            if not upload_record.data:
                return {'success': False, 'error': 'Failed to create upload record'}
            
            record_id = upload_record.data[0]['id']
            
            # è§£æxlsx
            parse_result = self.parse_xlsx(file_content)
            
            if not parse_result['success']:
                # æ›´æ–°ä¸Šä¼ è®°å½•ä¸ºå¤±è´¥
                self.supabase.table('qa_upload_records').update({
                    'status': 'failed',
                    'error_message': parse_result.get('error', 'Parse failed'),
                    'completed_at': datetime.utcnow().isoformat()
                }).eq('id', record_id).execute()
                
                return parse_result
            
            qa_list = parse_result['data']
            total_count = len(qa_list)
            success_count = 0
            failed_count = 0
            
            # æ‰¹é‡æ’å…¥QA
            for qa_data in qa_list:
                try:
                    result = self.create_qa_item(
                        knowledge_base_id=knowledge_base_id,
                        question=qa_data['question'],
                        answer=qa_data['answer'],
                        similar_questions=qa_data['similar_questions'],
                        source='batch'
                    )
                    
                    if result['success']:
                        success_count += 1
                    else:
                        failed_count += 1
                        
                except Exception as e:
                    logger.error(f"Error inserting QA: {e}")
                    failed_count += 1
            
            # æ›´æ–°ä¸Šä¼ è®°å½•
            self.supabase.table('qa_upload_records').update({
                'total_count': total_count,
                'success_count': success_count,
                'failed_count': failed_count,
                'status': 'completed' if failed_count == 0 else ('failed' if success_count == 0 else 'completed'),
                'error_message': f"éƒ¨åˆ†å¤±è´¥: {failed_count}æ¡" if failed_count > 0 and success_count > 0 else None,
                'completed_at': datetime.utcnow().isoformat()
            }).eq('id', record_id).execute()
            
            logger.info(f"Batch upload completed: {success_count} success, {failed_count} failed")
            
            return {
                'success': True,
                'record_id': record_id,
                'total': total_count,
                'success_count': success_count,
                'failed_count': failed_count,
                'parse_errors': parse_result.get('errors', [])
            }
            
        except Exception as e:
            logger.error(f"Error in batch upload: {e}")
            return {'success': False, 'error': str(e)}
    
    def list_upload_records(
        self,
        knowledge_base_id: str,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """
        è·å–ä¸Šä¼ è®°å½•åˆ—è¡¨
        
        Args:
            knowledge_base_id: çŸ¥è¯†åº“ID
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
        
        Returns:
            ä¸Šä¼ è®°å½•åˆ—è¡¨
        """
        try:
            query = self.supabase.table('qa_upload_records').select('*', count='exact')
            query = query.eq('knowledge_base_id', knowledge_base_id)
            
            offset = (page - 1) * page_size
            query = query.order('created_at', desc=True)
            query = query.range(offset, offset + page_size - 1)
            
            result = query.execute()
            
            total = result.count if result.count else 0
            total_pages = (total + page_size - 1) // page_size
            
            return {
                'success': True,
                'data': result.data or [],
                'pagination': {
                    'page': page,
                    'page_size': page_size,
                    'total': total,
                    'total_pages': total_pages
                }
            }
            
        except Exception as e:
            logger.error(f"Error listing upload records: {e}")
            return {'success': False, 'error': str(e), 'data': [], 'pagination': {}}
    
    def update_qa_status(self, qa_id: str, status: str) -> Dict[str, Any]:
        """
        æ›´æ–°QAå­¦ä¹ çŠ¶æ€
        
        Args:
            qa_id: QA ID
            status: æ–°çŠ¶æ€ (pending/learned/failed)
        
        Returns:
            æ›´æ–°ç»“æœ
        """
        return self.update_qa_item(qa_id, status=status)
    
    def update_qa_status_batch(self, qa_ids: List[str], status: str) -> Dict[str, Any]:
        """
        æ‰¹é‡æ›´æ–°QAå­¦ä¹ çŠ¶æ€
        
        Args:
            qa_ids: QA IDåˆ—è¡¨
            status: æ–°çŠ¶æ€
        
        Returns:
            æ›´æ–°ç»“æœ
        """
        try:
            result = self.supabase.table('qa_items').update({'status': status}).in_('id', qa_ids).execute()
            
            logger.info(f"Updated {len(qa_ids)} QA items to status: {status}")
            return {'success': True, 'message': f'Updated {len(qa_ids)} QA items'}
            
        except Exception as e:
            logger.error(f"Error batch updating QA status: {e}")
            return {'success': False, 'error': str(e)}

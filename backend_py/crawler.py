"""
1.1.12: URLçˆ¬è™«æ¨¡å— - é‡æ„ç‰ˆæœ¬
å®Œå…¨æŒ‰ç…§å‚è€ƒä»£ç å®ç°ï¼Œä½¿ç”¨ Selenium + unstructured åº“
"""

import os
import time
import re
import urllib.parse
import asyncio
from typing import List, Dict, Any, Optional, Literal, Union
import logging

import requests
from langchain_core.documents import Document
from langchain_community.document_loaders import PlaywrightURLLoader, UnstructuredURLLoader
from langchain_community.document_loaders.base import BaseLoader

# 1.1.12: é…ç½®æ—¥å¿—ï¼ˆä»…åœ¨å¼€å‘ç¯å¢ƒè¾“å‡ºï¼‰
logger = logging.getLogger(__name__)
if os.getenv("ENV") == "development":
    logging.basicConfig(level=logging.INFO)
else:
    logging.basicConfig(level=logging.WARNING)


# 1.1.12: è¾…åŠ©å‡½æ•°
def is_valid_url(s: str) -> bool:
    """æ£€æŸ¥URLæ˜¯å¦æœ‰æ•ˆï¼ˆéç©ºä¸”éç©ºç™½ï¼‰"""
    if s == "" or s.isspace():
        return False
    return True


def is_url_accessible(url: str) -> bool:
    """æ£€æŸ¥URLæ˜¯å¦å¯è®¿é—®"""
    if not is_valid_url(url):
        return False
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 200:
            return True
        else:
            if os.getenv("ENV") == "development":
                logger.info(f"First response [{response.status_code}] for {url}")
            return True
    except:
        return False


def replace_special_char(text: str) -> str:
    """æ¸…ç†ç‰¹æ®Šå­—ç¬¦å’Œé‡å¤æ ‡ç‚¹"""
    return re.sub(r"([ â– â—¼â€¢ï¼Šâ€¦â€” ï‚Ÿâ—âš«]+|[Â·\.~â€¢ã€â€”'}]{3,})", ' ', text)


# 1.1.12: SeleniumChromeURLLoader ç±»
class SeleniumChromeURLLoader(BaseLoader):
    """
    Loader that uses Selenium and Chrome to load a page and unstructured to load the html.
    This is useful for loading pages that require javascript to render.

    Attributes:
        urls (List[str]): List of URLs to load.
        continue_on_failure (bool): If True, continue loading other URLs on failure.
        browser (str): Use chrome as default browser.
        executable_path (Optional[str]): The path to the browser executable.
        headless (bool): If True, the browser will run in headless mode.
    """

    def __init__(
        self,
        urls: List[str],
        continue_on_failure: bool = True,
        browser: Literal["chrome", "firefox"] = "chrome",
        executable_path: Optional[str] = None,
        headless: bool = True,
        imageless: bool = True,
        infobarless: bool = True,
    ):
        """Load a list of URLs using Selenium and unstructured."""
        try:
            import selenium  # noqa:F401
        except ImportError:
            raise ValueError(
                "selenium package not found, please install it with "
                "`pip install selenium`"
            )

        try:
            import unstructured  # noqa:F401
        except ImportError:
            raise ValueError(
                "unstructured package not found, please install it with "
                "`pip install unstructured`"
            )

        self.urls = urls
        self.continue_on_failure = continue_on_failure
        self.browser = browser
        self.executable_path = executable_path
        self.headless = headless
        self.imageless = imageless
        self.infobarless = infobarless

    def _get_driver(self) -> Union["Chrome", "Firefox"]:
        """Create and return a WebDriver instance based on the specified browser.

        Raises:
            ValueError: If an invalid browser is specified.

        Returns:
            Union[Chrome, Firefox]: A WebDriver instance for the specified browser.
        """
        from selenium.webdriver import Chrome
        from selenium.webdriver.chrome.options import Options as ChromeOptions
        from selenium.webdriver.chrome.service import Service as ChromeService
        from webdriver_manager.chrome import ChromeDriverManager

        chrome_options = ChromeOptions()
        if self.headless:
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
        if self.imageless:
            chrome_options.add_argument("--blink-settings=imagesEnabled=false")
        if self.infobarless:
            chrome_options.add_argument("--disable-infobars")
        
        # 1.1.12: ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ç®¡ç† ChromeDriver
        if self.executable_path is None:
            try:
                # ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç† ChromeDriver
                service = ChromeService(ChromeDriverManager().install())
                return Chrome(service=service, options=chrome_options)
            except Exception as e:
                if os.getenv("ENV") == "development":
                    logger.warning(f"webdriver-manager failed, trying direct Chrome: {e}")
                # å›é€€åˆ°ç›´æ¥ä½¿ç”¨ Chromeï¼ˆä¾èµ–ç³»ç»Ÿ ChromeDriverï¼‰
                return Chrome(options=chrome_options)
        return Chrome(executable_path=self.executable_path, options=chrome_options)

    def load(self) -> List[Document]:
        """Load the specified URLs using Selenium and create Document instances.

        Returns:
            List[Document]: A list of Document instances with loaded content.
        """
        from unstructured.partition.html import partition_html

        docs: List[Document] = list()
        driver = self._get_driver()
        if os.getenv("ENV") == "development":
            logger.info(f"Selenium driver= {driver}")
            logger.info(f"load urls= {self.urls}")
        
        for url in self.urls:
            try:
                if os.getenv("ENV") == "development":
                    logger.info(f"[CORE_CALL] load url= {url}")
                driver.get(url)
                # 1.1.12: å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿ JavaScript åŠ¨æ€å†…å®¹å®Œå…¨åŠ è½½
                # å¯¹äº Vue.js ç­‰ SPA åº”ç”¨ï¼Œéœ€è¦æ›´é•¿çš„ç­‰å¾…æ—¶é—´
                time.sleep(8)  # ä»3ç§’å¢åŠ åˆ°8ç§’ï¼Œç¡®ä¿åŠ¨æ€å†…å®¹åŠ è½½å®Œæˆ
                
                # 1.1.12: å°è¯•ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼ˆç­‰å¾… body ä¸­æœ‰å®é™…å†…å®¹ï¼‰
                try:
                    from selenium.webdriver.support.ui import WebDriverWait
                    from selenium.webdriver.support import expected_conditions as EC
                    from selenium.webdriver.common.by import By
                    # ç­‰å¾… body ä¸­æœ‰æ–‡æœ¬å†…å®¹ï¼ˆè‡³å°‘100ä¸ªå­—ç¬¦ï¼‰
                    WebDriverWait(driver, 10).until(
                        lambda d: len(d.find_element(By.TAG_NAME, "body").text) > 100
                    )
                except:
                    # å¦‚æœç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­ä½¿ç”¨å›ºå®šç­‰å¾…æ—¶é—´åçš„å†…å®¹
                    pass
                
                title = driver.title
                page_content = driver.page_source
                
                # 1.1.12: å°è¯•è·å–ç¼–è¾‘å™¨å†…å®¹ï¼ˆå¦‚æœæ˜¯ Markdown ç¼–è¾‘å™¨ï¼‰
                try:
                    # ä½¿ç”¨ JavaScript è·å–æ‰€æœ‰ç¼–è¾‘å™¨å†…å®¹ï¼ˆåŒ…æ‹¬ Vue æ¸²æŸ“çš„å†…å®¹ï¼‰
                    editor_content_js = """
                    var editors = [];
                    // è·å–æ‰€æœ‰å¯èƒ½çš„ç¼–è¾‘å™¨å…ƒç´ 
                    var selectors = ['textarea', '[contenteditable="true"]', '.vditor-sv', '.vditor-textarea', '.editor', '#editor'];
                    selectors.forEach(function(selector) {
                        document.querySelectorAll(selector).forEach(function(el) {
                            var text = el.value || el.textContent || el.innerText || '';
                            if (text && text.trim().length > 50) {
                                editors.push({
                                    tag: el.tagName,
                                    text: text,
                                    id: el.id || '',
                                    className: el.className || ''
                                });
                            }
                        });
                    });
                    return editors;
                    """
                    editor_contents = driver.execute_script(editor_content_js)
                    
                    if editor_contents:
                        # åˆå¹¶æ‰€æœ‰ç¼–è¾‘å™¨å†…å®¹
                        all_editor_text = "\n\n".join([ed['text'] for ed in editor_contents if ed['text']])
                        if all_editor_text and len(all_editor_text) > 100:
                            if os.getenv("ENV") == "development":
                                logger.info(f"æ‰¾åˆ°ç¼–è¾‘å™¨å†…å®¹ï¼Œé•¿åº¦: {len(all_editor_text)} å­—ç¬¦")
                            # å°†ç¼–è¾‘å™¨å†…å®¹æ·»åŠ åˆ°é¡µé¢æºç ä¸­ï¼Œä¼˜å…ˆä½¿ç”¨ç¼–è¾‘å™¨å†…å®¹
                            page_content = f"{page_content}\n<!-- Editor Content -->\n{all_editor_text}"
                except Exception as editor_error:
                    if os.getenv("ENV") == "development":
                        logger.warning(f"è·å–ç¼–è¾‘å™¨å†…å®¹å¤±è´¥: {editor_error}")
                if os.getenv("ENV") == "development":
                    logger.info(f"load url end")
                
                # 1.1.12: ä¿®å¤ partition_html å¤„ç†æŸäº›ç½‘é¡µæ—¶çš„é”™è¯¯
                # å¦‚æœç›´æ¥ä¼  text å¤±è´¥ï¼ŒæŒ‰ç…§ chatmax é€»è¾‘åº”è¯¥æ ‡è®°ä¸ºè§£æå¤±è´¥
                try:
                    elements = partition_html(text=page_content)
                except Exception as parse_error:
                    if os.getenv("ENV") == "development":
                        logger.warning(f"partition_html failed: {parse_error}")
                    # 1.1.12: æŒ‰ç…§ chatmax é€»è¾‘ï¼Œpartition_html å¤±è´¥åº”è¯¥æ ‡è®°ä¸ºè§£æå¤±è´¥
                    # ä¸å†ä½¿ç”¨ BeautifulSoup å›é€€ï¼Œç›´æ¥åˆ›å»ºé”™è¯¯æ–‡æ¡£
                    error_reason = f"partition_html å¤„ç†å¤±è´¥ - {str(parse_error)}"
                    docs.append(Document(
                        page_content=f"è§£æå¤±è´¥: {error_reason}\nåŸå§‹URL: {url}",
                        metadata={
                            "source": url,
                            "title": url,
                            "url": url,
                            "error": error_reason
                        }
                    ))
                    continue
                
                text = "\n\n".join(
                    [replace_special_char(str(el).strip()) for el in elements if el is not None])
                metadata = {"source": url,
                            "title": title}
                if os.getenv("ENV") == "development":
                    logger.info(f"[CORE_CALL] url data, content={text}, meta={metadata}")
                docs.append(Document(page_content=text, metadata=metadata))
            except Exception as e:
                if self.continue_on_failure:
                    if os.getenv("ENV") == "development":
                        logger.error(f"[CORE_CALL] Error fetching or processing {url}, exception: {e}")
                else:
                    raise e
        driver.quit()
        return docs


# 1.1.12: loader_factory å‡½æ•°
def loader_factory(urls: List[str], loader_type: str):
    """æ ¹æ®ç±»å‹åˆ›å»ºä¸åŒçš„URLåŠ è½½å™¨"""
    if loader_type == "selenium":
        return SeleniumChromeURLLoader(urls=urls,)
    elif loader_type == "unstructured":
        return UnstructuredURLLoader(urls=urls,)
    elif loader_type == "playwright":
        return PlaywrightURLLoader(
            urls=urls,
            remove_selectors=["header", "footer"],
            continue_on_failure=False,
            headless=True,
        )
    else:
        return ValueError(("Invalid URL loader type"))


# 1.1.12: process_web_content å‡½æ•°ï¼ˆæŒ‰ç…§ chatmax é€»è¾‘ï¼‰
def process_web_content(decoded_url: str, omit_content: bool = False):
    """å¤„ç†ç½‘é¡µå†…å®¹ï¼Œä½¿ç”¨SeleniumåŠ è½½å™¨
    
    æŒ‰ç…§ chatmax é€»è¾‘ï¼š
    - å¦‚æœ docs ä¸ºç©ºï¼Œè¿”å›é”™è¯¯æ ‡è®°
    - å¦‚æœå†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œè¿”å›é”™è¯¯æ ‡è®°
    """
    urls = [decoded_url]
    loader = loader_factory(urls, "selenium")
    docs = loader.load()

    # 1.1.12: æŒ‰ç…§ chatmax é€»è¾‘ï¼Œå¦‚æœ docs ä¸ºç©ºï¼Œè¿”å›é”™è¯¯æ ‡è®°
    if not docs:
        return None, None, -1  # è¿”å› None è¡¨ç¤ºè§£æå¤±è´¥

    doc = docs[0]
    content = doc.page_content
    
    # 1.1.12: æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–è¿‡çŸ­ï¼ˆå°‘äº50å­—ç¬¦è§†ä¸ºæ— æ•ˆï¼‰
    if not content or not content.strip() or len(content.strip()) < 50:
        return None, None, -1  # è¿”å› None è¡¨ç¤ºè§£æå¤±è´¥
    
    word_count = len(content)

    if content:
        if omit_content:
            content = ""
        content = replace_special_char(content)

    return content, doc.metadata.get('title', ''), word_count


# 1.1.12: å¼‚æ­¥æ¥å£ - ä¿æŒä¸ workflow.py çš„å…¼å®¹æ€§
async def crawl_urls(urls: List[str], options: Optional[Dict[str, Any]] = None) -> List[Document]:
    """
    1.1.12: æ‰¹é‡çˆ¬å–å¤šä¸ªURLï¼ˆå¼‚æ­¥æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨åŒæ­¥çš„Seleniumï¼‰
    
    Args:
        urls: URLåˆ—è¡¨
        options: çˆ¬å–é€‰é¡¹ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼Œä½†SeleniumåŠ è½½å™¨ä¸ä½¿ç”¨ï¼‰
    
    Returns:
        Documentåˆ—è¡¨
    """
    if not urls:
        return []
    
    if os.getenv("ENV") == "development":
        logger.info(f"ğŸ•·ï¸ å¼€å§‹æ‰¹é‡çˆ¬å– {len(urls)} ä¸ªURL")
    
    # 1.1.12: ä½¿ç”¨ asyncio.to_thread åœ¨å¼‚æ­¥ç¯å¢ƒä¸­æ‰§è¡ŒåŒæ­¥çš„Seleniumä»£ç 
    def sync_crawl():
        """åŒæ­¥çˆ¬å–å‡½æ•°"""
        loader = loader_factory(urls, "selenium")
        return loader.load()
    
    try:
        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥ä»£ç 
        docs = await asyncio.to_thread(sync_crawl)
        
        # 1.1.12: æŒ‰ç…§ chatmax é€»è¾‘æ£€æŸ¥æ–‡æ¡£
        valid_docs = []
        error_docs = []
        
        for url in urls:
            # æŸ¥æ‰¾å¯¹åº” URL çš„æ–‡æ¡£
            url_doc = None
            for doc in docs:
                if doc.metadata.get('source') == url:
                    url_doc = doc
                    break
            
            # 1.1.12: æŒ‰ç…§ chatmax é€»è¾‘åˆ¤æ–­è§£æå¤±è´¥
            # æ¡ä»¶1: docs ä¸ºç©ºï¼ˆæ²¡æœ‰æ‰¾åˆ°å¯¹åº” URL çš„æ–‡æ¡£ï¼‰
            # æ¡ä»¶2: æ–‡æ¡£å†…å®¹ä¸ºç©ºæˆ–è¿‡çŸ­ï¼ˆå°‘äº50å­—ç¬¦ï¼‰
            # æ¡ä»¶3: æ–‡æ¡£å†…å®¹åŒ…å«é”™è¯¯æ ‡è®°
            is_error = False
            error_reason = None
            
            if not url_doc:
                is_error = True
                error_reason = "è§£æå¤±è´¥: æœªè·å–åˆ°æ–‡æ¡£å†…å®¹"
            elif not url_doc.page_content or not url_doc.page_content.strip():
                is_error = True
                error_reason = "è§£æå¤±è´¥: æ–‡æ¡£å†…å®¹ä¸ºç©º"
            elif len(url_doc.page_content.strip()) < 50:
                is_error = True
                error_reason = "è§£æå¤±è´¥: æ–‡æ¡£å†…å®¹è¿‡çŸ­"
            elif 'error' in url_doc.metadata or 'çˆ¬å–å¤±è´¥' in url_doc.page_content or 'è§£æå¤±è´¥' in url_doc.page_content:
                # å¦‚æœæ–‡æ¡£å·²ç»æ˜¯é”™è¯¯æ–‡æ¡£ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸å†åˆ›å»ºæ–°çš„
                is_error = True
                error_reason = url_doc.metadata.get('error', 'è§£æå¤±è´¥: æ–‡æ¡£åŒ…å«é”™è¯¯æ ‡è®°')
            
            if is_error:
                # å¦‚æœæ–‡æ¡£å·²ç»æ˜¯é”™è¯¯æ–‡æ¡£ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦åˆ™åˆ›å»ºæ–°çš„é”™è¯¯æ–‡æ¡£
                if url_doc and 'error' in url_doc.metadata:
                    error_docs.append(url_doc)
                else:
                    # åˆ›å»ºé”™è¯¯æ–‡æ¡£
                    error_docs.append(Document(
                        page_content=f"è§£æå¤±è´¥: {error_reason}\nåŸå§‹URL: {url}",
                        metadata={
                            "source": url,
                            "title": url,
                            "url": url,
                            "error": error_reason or "è§£æå¤±è´¥"
                        }
                    ))
            else:
                valid_docs.append(url_doc)
        
        # 1.1.12: å¦‚æœæ‰€æœ‰ URL éƒ½å¤±è´¥ï¼Œè¿”å›é”™è¯¯æ–‡æ¡£ï¼›å¦åˆ™è¿”å›æ··åˆç»“æœ
        result_docs = valid_docs + error_docs
        
        if os.getenv("ENV") == "development":
            logger.info(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆ: æˆåŠŸ {len(valid_docs)}/{len(urls)} ä¸ªURL, å¤±è´¥ {len(error_docs)} ä¸ª")
        
        return result_docs
    except Exception as e:
        if os.getenv("ENV") == "development":
            logger.error(f"âŒ çˆ¬å–å¤±è´¥: {str(e)}")
        # è¿”å›é”™è¯¯æ–‡æ¡£åˆ—è¡¨
        return [
            Document(
                page_content=f"è§£æå¤±è´¥: {str(e)}\nåŸå§‹URL: {url}",
                metadata={
                    "source": url,
                    "title": url,
                    "url": url,
                    "error": str(e)
                }
            )
            for url in urls
        ]
